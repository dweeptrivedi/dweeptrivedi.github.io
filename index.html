<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Dweep Trivedi</title>
  
  <meta name="author" content="Dweep Trivedi">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/icon1.png">
</head>
  
<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/dweep_image2.jpg"><img style="width:80%;max-width:100%" alt="profile photo" src="images/dweep_image2.jpg" class="hoverZoomLink"></a>
            </td>
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Dweep Trivedi</name>
              </p>
              <p>I am a visiting researcher at <a href="https://www.clvrai.com/"> Cognitive Learning for Vision and Robotics Lab (CLVR) </a> at <a href= "https://www.cs.usc.edu/">University of Southern California</a>, advised by <a href="https://viterbi-web.usc.edu/~limjj/"> Prof. Joseph Lim </a>.
              </p>
              <p>
                Previously, I finished my Masterâ€™s in Computer Science at <a href="https://www.cs.usc.edu/">University of Southern California</a>, where I worked under the guidance of <a href= "https://sites.google.com/view/skim-home/home" >Dr. Seon Ho Kim</a> and <a href= "https://viterbi-web.usc.edu/~liu32/">Prof. Yan Liu</a>. Earlier, I spent 2 years working as Software Development Engineer in <a href="https://www.juniper.net/us/en.html" >Juniper Networks, Bangalore </a>. I did my undergrad in Information and Communication Technology at <a href="https://www.daiict.ac.in/"> DA-IICT, Gandhinagar</a>.
              </p>
              <p style="text-align:center">
                <a href="mailto:dweeptrivedi1994@gmail.com">Email</a> &nbsp|&nbsp
                <a href="data/DweepTrivedi_CV.pdf">CV</a> &nbsp|&nbsp
                <a href="https://scholar.google.com/citations?user=Jf9i6GQAAAAJ&hl=en">Google Scholar</a> &nbsp|&nbsp
                
                <a href="https://github.com/dweeptrivedi">Github</a> &nbsp|&nbsp
                <a href="https://twitter.com/dweeptrivedi">Twitter</a> &nbsp|&nbsp
                <a href="https://www.linkedin.com/in/dweep-trivedi">Linkedin</a> 
              </p>
            </td>
           
          </tr>
        </tbody></table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in Deep Learning, Programmatic Reinforcement Learning, Continual Learning and Robot Learning. 
              </p>
            </td>
          </tr>
        </tbody></table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


          <tr onmouseout="clipnerf_stop()" onmouseover="clipnerf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <a href="images/paper_image_learning.JPG"><img style="width:100%;max-width:100%" alt="profile photo" src="images/paper_image_learning.JPG" class="hoverZoomLink"></a>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2108.13643">
                <papertitle>Learning to Synthesize Programs as Interpretable and Generalizable Policies</papertitle>
              </a>
              <br>
              <strong>Dweep Trivedi*</strong>,
              <a href="https://jesbu1.github.io/">Jesse Zhang*</a>,
              <a href="https://shaohua0116.github.io/">Shao-Hua Sun*</a>,
              <a href="https://viterbi-web.usc.edu/~limjj/">Joseph J Lim</a>
              
              <br>
        <em>Thirty-Fifth Conference on Neural Information Processing Systems</em>, 2021
              <br>
              [ <a href="https://papers.nips.cc/paper/2021/file/d37124c4c79f357cb02c655671a432fa-Paper.pdf">PDF</a> ]
        
                [ <a href="https://shaohua0116.github.io/bibtex/leaps.txt">BibTex</a> ]
                [ <a href="https://clvrai.github.io/leaps/">Code</a> ]
                [ <a href="https://clvrai.github.io/leaps/">Project Page</a> ]
       
              <p></p>
              <p>We present a framework that learns to synthesize a program, detailing the procedure to solve a task in a flexible and expressive manner, solely from reward signals. To alleviate the difficulty of learning to compose programs to induce the desired agent behavior from scratch, we propose to learn a program embedding space that continuously parameterizes diverse behaviors in an unsupervised manner and then search over the learned program embedding space to yield a program that maximizes the return for a given task.</p>
            </td>
          </tr>
          
          
          
          <tr onmouseout="clipnerf_stop()" onmouseover="clipnerf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <a href="images/paper_image_multi1.JPG"><img style="width:100%;max-width:100%" alt="profile photo" src="images/paper_image_multi1.JPG" class="hoverZoomLink"></a>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2010.15891">
                <papertitle>Multi-agent trajectory prediction with fuzzy query attention
              </a>
              <br>
              <a href="http://www-scf.usc.edu/~nkamra/"> Nitin Kamra </a>, 
              Hao Zhu,
              <strong>Dweep Trivedi</strong>,
              Ming Zhang,
              <a href="https://viterbi-web.usc.edu/~liu32/">Yan Liu </a>
              
              <br>
        <em>NeurIPS</em>, 2020
              <br>
              [ <a href="https://arxiv.org/pdf/2010.15891.pdf">PDF</a> ]
      
              [ <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:l6KJwi0ecywJ:scholar.google.com/&output=citation&scisdr=CgXmK2d-EMDjhTfnOv8:AAGBfm0AAAAAYbDhIv-G-U77IJsclkI8rJ1GZ-DVwD8M&scisig=AAGBfm0AAAAAYbDhIpTFxai8BpN8585JgnK0O5b-xArf&scisf=4&ct=citation&cd=-1&hl=en">BibTex</a> ]
              [ <a href="https://github.com/nitinkamra1992/FQA">Code</a> ]
              <p></p>
              <p>We present a general architecture to address multi-agent trajectory prediction which models the crucial inductive biases of motion, namely, inertia, relative motion, intents and interactions. Specifically, we propose a relational model to flexibly model interactions between agents in diverse environments. At the core of our model lies a novel attention mechanism which models interactions by making continuous-valued (fuzzy) decisions and learning the corresponding responses. Our architecture demonstrates significant performance gains over existing state-of-the-art predictive models in diverse domains such as human crowd trajectories, US freeway traffic, NBA sports data and physics datasets.</p>
            </td>
          </tr>
          
          <tr onmouseout="clipnerf_stop()" onmouseover="clipnerf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <a href="images/paper_image_damag2.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/paper_image_damag2.jpg" class="hoverZoomLink"></a>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href = "https://ieeexplore.ieee.org/document/9377833">
                <papertitle>Yet another deep learning approach for road damage detection using ensemble learning
              </a>
              <br>
              Vinuta Hegde*, 
              <strong>Dweep Trivedi*</strong>,
              <a href="http://www-scf.usc.edu/~alfarrar/">Abdullah Alfarrarjeh</a>,
              Aditi Deepak,
              <a href="https://sites.google.com/view/skim-home/home">Seon Ho Kim</a>,
                <a href= "https://infolab.usc.edu/Shahabi/"> Cyrus Shahabi </a>
              
              <br>
        <em>IEEE International Conference on Big Data (Big Data)</em>, 2020
              <br>
              [ <a href="https://infolab.usc.edu/DocsDemos/BigDataRDD2020.pdf">PDF</a> ]
        
               [ <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:5qvy8tD3MEUJ:scholar.google.com/&output=citation&scisdr=CgXmK2d-EMDjhTfn3Ws:AAGBfm0AAAAAYbDhxWv_b-V2-WnxjTL0ntpFPxVpa-Nr&scisig=AAGBfm0AAAAAYbDhxYmvxulS7zaDmj74DPo9mqUtUAEy&scisf=4&ct=citation&cd=-1&hl=en">BibTex</a> ]
               [ <a href="https://github.com/USC-InfoLab/rddc2020">Code</a> ]
              <p></p>
              <p>This paper introduces deep learningbased image analysis for road damage detection and classification. Our ensemble learning approaches with test time augmentation were thoroughly evaluated using the 2020 IEEE Big Data Global Road Damage Detection Challenge Dataset. Experimental results show that our approaches achieved an F1 score of up to 0.67, allowing us to win the Challenge.</p>
            </td>
          </tr>
          
          
          <tr onmouseout="clipnerf_stop()" onmouseover="clipnerf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <a href="images/paper_image_graffiti2.JPG"><img style="width:100%;max-width:100%" alt="profile photo" src="images/paper_image_graffiti2.JPG" class="hoverZoomLink"></a>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href= "https://ieeexplore.ieee.org/document/8803286">
                <papertitle>Recognizing material of a covered object: A case study with graffiti
              </a>
              <br>
              
              <a href="http://www-scf.usc.edu/~alfarrar/">Abdullah Alfarrarjeh*</a>,
              <strong>Dweep Trivedi*</strong>,
                <a href="https://sites.google.com/view/skim-home/home">Seon Ho Kim</a>,
              Hyunjun Park, Chao Huang,
                <a href= "https://infolab.usc.edu/Shahabi/"> Cyrus Shahabi </a>
              
              <br>
        <em>IEEE International Conference on Image Processing (ICIP)</em>, 2019
              <br>
              [ <a href="http://mediaq.usc.edu:8080/TVDP/papers/IEEE_ICIP_graffiti.pdf">PDF</a> ]
        
              [ <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:QKX1K4VLOoYJ:scholar.google.com/&output=citation&scisdr=CgXmK2d-EMDjhTfYHSQ:AAGBfm0AAAAAYbDeBSQgHDgafaPXkXW4ozuN3Zl7NKmp&scisig=AAGBfm0AAAAAYbDeBYEtJ6ZOjmgmASLwtPqifHwD4Vqa&scisf=4&ct=citation&cd=-1&hl=en">BibTex</a> ]
       
              <p></p>
              <p>This paper introduces the problem of recognizing covered materials which are distorted visually (e.g., materials covered by graffiti). We propose a set of approaches to solve this problem using a class of deep learning and transfer learning models, and evaluate our approaches empirically using a large-scale real world dataset that displays street scenes containing various materials which are covered with graffiti. Our experiments show that recognizing covered materials using the state-of-the-art approach for material recognition produced an mAP of 19%, while our proposed approach achieved an mAP of 60%.</p>
            </td>
          </tr>
          
          <tr onmouseout="clipnerf_stop()" onmouseover="clipnerf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <a href="images/paper_image_damag1.JPG"><img style="width:100%;max-width:100%" alt="profile photo" src="images/paper_image_damag1.JPG" class="hoverZoomLink"></a>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/document/8621899">
                <papertitle>A deep learning approach for road damage detection from smartphone images
              </a>
              <br>
              
              <a href="http://www-scf.usc.edu/~alfarrar/">Abdullah Alfarrarjeh*</a>,
              <strong>Dweep Trivedi*</strong>,
                <a href="https://sites.google.com/view/skim-home/home">Seon Ho Kim</a>,
              <a href= "https://infolab.usc.edu/Shahabi/"> Cyrus Shahabi </a>
              
              <br>
        <em>IEEE International Conference on Big Data (Big Data)</em>, 2018
              <br>
              [ <a href="https://infolab.usc.edu/DocsDemos/IEEE_BigData_RoadDamageDetection.pdf">PDF</a> ]
        
              [ <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:ixejBOKojc8J:scholar.google.com/&output=citation&scisdr=CgXmK2d-EMDjhTfZdiA:AAGBfm0AAAAAYbDfbiD_Wg1qor_1SaVIwdjEbj1HkTY_&scisig=AAGBfm0AAAAAYbDfbhEIDPwXaU2bZHslBnbTItXdJbO0&scisf=4&ct=citation&cd=-1&hl=en">BibTex</a> ]
              [ <a href="https://github.com/dweeptrivedi/road-damage-detection">Code</a> ]
              <p></p>
              <p>This paper describes a road damage type detection and classification solution submitted to the IEEE BigData Cup Challenge 2018. Our solution is based on the state-of-the-art deep learning methods for an object detection task. In particular, our approach utilizes an object detection algorithm to detect various types of road damages by training the detector on different image examples categorized into a set of damages defined by Japan Road Association. We evaluated our approach thoroughly using different versions of trained models. Our experiments show that our approach was able to achieve an F1 score up to 0.62.</p>
            </td>
          </tr>
          
         
          
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <br>
              <p align="right">
                <font size="2">
                  Credits to the
                  <a href="https://jonbarron.info/">
                    <font size="2">
                      The Simplest template!
                    </font>
                  </a>
                </font>
              </p>
            </td>
          </tr>
        </table>
        
        </body>
        

</html>
